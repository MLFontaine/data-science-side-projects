{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping web data for use with a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data is scraped from a columnist's email Q&A articles which they've published once a week for several years. We'll run them through a neural network that should imitate the style of the column.\n",
    "- Step 1: Crawl this site for all articles: http://deadspin.com/tag/funbag\n",
    "- Step 2: Parse just the text content, with some html tagging into individual html files\n",
    "- Step 3: Concatenate into one large file for feeding into the RNN\n",
    "- Output: The total file size is 10 MB, which took about 11 hours to run on my laptop. The output of the neural network for 200,000 characters is save in neural_net_output.html\n",
    "- To do: The output is recognizably in the style of the column. It could be improved however. Different parameters for the neural network should be experimented with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the URLS for each html page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scrapy spider in the funbag_spider.py file, and run it from the shell here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! scrapy runspider funbag_spider.py -o funbag_urls.json &>/dev/null "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load URLs from JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://adequateman.deadspin.com/whats-the-best-store-to-daydream-about-robbing-1796232076', 'http://adequateman.deadspin.com/should-you-ask-people-their-politics-before-dating-them-1796052163', 'http://adequateman.deadspin.com/is-an-unbeaten-playoff-run-more-impressive-than-73-wins-1795847201']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('funbag_urls.json') as url_file:    \n",
    "    url_data = json.load(url_file)\n",
    "\n",
    "all_urls = []\n",
    "for place in url_data:\n",
    "    all_urls.append(str(place.values()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse, sanitize, and save each of the html pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io #to fix a problem with writing unicode\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "\n",
    "def oneFullPageParse(url, outfile):\n",
    "    fo = io.open(os.path.join(os.getcwd(), 'full_page_files', outfile), 'w', encoding = 'utf-8')\n",
    "    funbag = urllib2.urlopen(url)\n",
    "    soup = BeautifulSoup(funbag,'html5lib')\n",
    "    for anchor in soup.find_all(['p', 'blockquote'], class_ = ''): \n",
    "        if anchor.parent.name == 'blockquote': #prevents repeating the <p> tags inside\n",
    "            continue\n",
    "        fo.write(anchor.prettify(formatter=\"html\"))\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 586.253000021\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#loop through all urls to generate cleaned up pages\n",
    "for idx, row in enumerate(all_urls):\n",
    "    my_outfile = str(idx) + '.html'\n",
    "    oneFullPageParse(row, my_outfile)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print 'Total time:', total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all .html files into one file using a simple bash script. This is now ready to be run in torch-rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! cat *.html > all.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train character level language model using LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See:\n",
    "\n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "https://github.com/karpathy/char-rnn\n",
    "\n",
    "https://github.com/jcjohnson/torch-rnn\n",
    "\n",
    "This last one is the best model to use...\n",
    "Here's an installation guide for OSX:\n",
    "http://www.jeffreythompson.org/blog/2016/03/25/torch-rnn-mac-install/\n",
    "\n",
    "There was an installation issue when I tried to train the model. It was fixed by following the comment from 'tbornt' here: https://github.com/deepmind/torch-hdf5/issues/83#issuecomment-254427843"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code from the shell for the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! python scripts/preprocess.py --input_txt data/funbag.txt --output_h5 data/funbag.h5 --output_json data/funbag.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model from shell using torch/lua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! th train.lua -input_h5 data/funbag.h5 -input_json data/funbag.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View output by writing to file using a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! th sample.lua -checkpoint cv/checkpoint_159500.t7 -length 200000 -gpu -1 > outputs/funbag_159500_output3.html -temperature 0.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
